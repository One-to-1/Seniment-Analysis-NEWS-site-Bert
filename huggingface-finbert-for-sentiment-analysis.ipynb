{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"font-family: Verdana; letter-spacing: 2px; color:#000000; font-size:300%; padding: 0px; text-align:center;\">\n","    <b>ðŸ¤— FinBERT for Sentiment Analysis ðŸ¤—</b>\n","    \n","    \n","In this short notebook I will show how you can use FinBERT easily for sentiment analysis. \n","FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. [Financial PhraseBank](https://www.researchgate.net/publication/251231107_Good_Debt_or_Bad_Debt_Detecting_Semantic_Orientations_in_Economic_Texts) by Malo et al. (2014) is used for fine-tuning. For more details, please see the paper [FinBERT: Financial Sentiment Analysis with Pre-trained Language Models](https://arxiv.org/abs/1908.10063) and our related blog post on Medium.\n","\n","The model will give softmax outputs for three labels: positive, negative or neutral."]},{"cell_type":"markdown","metadata":{},"source":["# 1 SETUP"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-23T06:51:00.882417Z","iopub.status.busy":"2023-11-23T06:51:00.881889Z","iopub.status.idle":"2023-11-23T06:51:08.766077Z","shell.execute_reply":"2023-11-23T06:51:08.764203Z","shell.execute_reply.started":"2023-11-23T06:51:00.882379Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import scipy\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification"]},{"cell_type":"markdown","metadata":{},"source":["I now read the input file. I will add the column headers, since they are not present in the csv file. "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T06:52:47.498803Z","iopub.status.busy":"2023-11-23T06:52:47.497141Z","iopub.status.idle":"2023-11-23T06:52:47.57835Z","shell.execute_reply":"2023-11-23T06:52:47.5775Z","shell.execute_reply.started":"2023-11-23T06:52:47.49875Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentiment</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>According to Gran , the company has no plans t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>neutral</td>\n","      <td>Technopolis plans to develop in stages an area...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>negative</td>\n","      <td>The international electronic industry company ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>positive</td>\n","      <td>With the new production plant the company woul...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>positive</td>\n","      <td>According to the company 's updated strategy f...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Sentiment                                               Text\n","0   neutral  According to Gran , the company has no plans t...\n","1   neutral  Technopolis plans to develop in stages an area...\n","2  negative  The international electronic industry company ...\n","3  positive  With the new production plant the company woul...\n","4  positive  According to the company 's updated strategy f..."]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('all-data.csv', encoding='unicode_escape', names=['Sentiment', 'Text'])\n","data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T06:52:53.083435Z","iopub.status.busy":"2023-11-23T06:52:53.082974Z","iopub.status.idle":"2023-11-23T06:52:53.091873Z","shell.execute_reply":"2023-11-23T06:52:53.090582Z","shell.execute_reply.started":"2023-11-23T06:52:53.083401Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(4846, 2)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"markdown","metadata":{},"source":["In total we have 4846 observations for those we can predict the sentiment. "]},{"cell_type":"markdown","metadata":{},"source":["# 2 PREPARATION\n","The first thing we do, is to separate the columns. The `Text` column will be our `X` which we will feed into FinBERT and `Sentiment` is our target in which we are interested, I will safe it into `y`. \n","There is no need to specify a train or testset, we will use the pretrained model directly to predict the sentiment. "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T06:54:04.959139Z","iopub.status.busy":"2023-11-23T06:54:04.958711Z","iopub.status.idle":"2023-11-23T06:54:04.965473Z","shell.execute_reply":"2023-11-23T06:54:04.964212Z","shell.execute_reply.started":"2023-11-23T06:54:04.959105Z"},"trusted":true},"outputs":[],"source":["X = data['Text'].to_list()\n","y = data['Sentiment'].to_list()"]},{"cell_type":"markdown","metadata":{},"source":["In the next step I will directly download [FinBERT](https://huggingface.co/ProsusAI/finbert) directly from Huggingface. "]},{"cell_type":"code","execution_count":6,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-11-23T06:54:36.624512Z","iopub.status.busy":"2023-11-23T06:54:36.62411Z","iopub.status.idle":"2023-11-23T06:54:43.263466Z","shell.execute_reply":"2023-11-23T06:54:43.262227Z","shell.execute_reply.started":"2023-11-23T06:54:36.624483Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"]},{"cell_type":"markdown","metadata":{},"source":["# 3 PREDICT\n","Finally we are able to loop over the X list and predict for every entry the label. I will safe the predicted label as well as the probability for that class."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T06:55:52.808642Z","iopub.status.busy":"2023-11-23T06:55:52.807889Z","iopub.status.idle":"2023-11-23T07:02:59.966105Z","shell.execute_reply":"2023-11-23T07:02:59.964976Z","shell.execute_reply.started":"2023-11-23T06:55:52.8086Z"},"trusted":true},"outputs":[],"source":["preds = []\n","preds_proba = []\n","tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n","for x in X:\n","    with torch.no_grad():\n","        input_sequence = tokenizer(x, return_tensors=\"pt\", **tokenizer_kwargs)\n","        logits = model(**input_sequence).logits\n","        scores = {\n","        k: v\n","        for k, v in zip(\n","            model.config.id2label.values(),\n","            scipy.special.softmax(logits.numpy().squeeze()),\n","        )\n","    }\n","    sentimentFinbert = max(scores, key=scores.get)\n","    probabilityFinbert = max(scores.values())\n","    preds.append(sentimentFinbert)\n","    preds_proba.append(probabilityFinbert)"]},{"cell_type":"markdown","metadata":{},"source":["# 4 EVALUATION\n","LetÂ´s check the performance of our model quick. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T07:05:29.620141Z","iopub.status.busy":"2023-11-23T07:05:29.619674Z","iopub.status.idle":"2023-11-23T07:05:29.642376Z","shell.execute_reply":"2023-11-23T07:05:29.640901Z","shell.execute_reply.started":"2023-11-23T07:05:29.620105Z"},"trusted":true},"outputs":[],"source":["print(f'Accuracy-Score: {accuracy_score(y, preds)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-23T07:05:32.334837Z","iopub.status.busy":"2023-11-23T07:05:32.334376Z","iopub.status.idle":"2023-11-23T07:05:32.419625Z","shell.execute_reply":"2023-11-23T07:05:32.418511Z","shell.execute_reply.started":"2023-11-23T07:05:32.334803Z"},"trusted":true},"outputs":[],"source":["print(classification_report(y, preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-11-23T07:06:36.894948Z","iopub.status.busy":"2023-11-23T07:06:36.894437Z","iopub.status.idle":"2023-11-23T07:06:37.266729Z","shell.execute_reply":"2023-11-23T07:06:37.26537Z","shell.execute_reply.started":"2023-11-23T07:06:36.894914Z"},"trusted":true},"outputs":[],"source":["cm = confusion_matrix(y, preds)\n","cm_matrix = pd.DataFrame(data=cm)\n","plt.figure(figsize=(10,10))\n","sns.heatmap(cm_matrix, annot=True, cmap='YlGnBu', fmt='d')\n","plt.title('Confusion Matrix')\n","plt.show();"]},{"cell_type":"markdown","metadata":{},"source":["The output is really good. Around 89% accuracy without any fine-tuning. "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":622510,"sourceId":1192499,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
